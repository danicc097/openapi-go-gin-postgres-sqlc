#!/bin/bash
# shellcheck disable=1091,2155,2068,2086,2031

source "${BASH_SOURCE%/*}/.helpers.sh"
source "${BASH_SOURCE%/*}/scripts/deps-check.sh"

set -Eeo pipefail

trap killgroup SIGINT
trap errtrap SIGUSR1

killgroup() {
  printf "\nkilling spawned processes...\n"
  kill 0
  exit 1
}

errtrap() {
  printf "\nExiting due to propagated error...\n"
  exit 1
}

ensure_pwd_is_top_level

source ".envrc"

export PROC=$$
export GIT_USER_ID=danicc097
export GIT_REPO_ID=openapi-go-gin-postgres-sqlc
export GO_POST_PROCESS_FILE="/usr/bin/env gofmt -w -s"
export GENVERS=6.0.1

readonly SPEC="openapi.yaml"
readonly OPENAPI_GEN_OUT_DIR="internal"
readonly OPENAPI_GEN_DIR="$OPENAPI_GEN_OUT_DIR/gen"
readonly PROTO_DIR="internal/pb"
readonly TEMPLATE_DIR="internal/go-gin-server-templates"
readonly BIN_DIR=$(dirname "${BASH_SOURCE[0]}")
readonly PG_REPO="internal/repos/postgresql"
readonly MAX_COMMENT_LEN=88
readonly MAX_FNAME_LOG_LEN=12
readonly DUMPS_FOLDER="$HOME/openapi_go_gin_postgres_dumps"

pids=()
env="dev"
dump_prefix="dump_${env}_"

# log for any function output.
xlog() {
  fname="${FUNCNAME[1]#*.}"
  if [[ ${#fname} -gt $MAX_FNAME_LOG_LEN ]]; then
    fname="${fname:0:$MAX_FNAME_LOG_LEN}…"
  fi
  if [[ "$CMD" = "$fname" ]]; then
    cat # remove logging for the command itself
  else
    fn=$(printf "%*s |\n" $((MAX_FNAME_LOG_LEN + 1)) "$fname")
    sed -ue "s/^/${BLUE}$fn${OFF} /"
  fi
}

# log stderr for any function output.
# sed is buffering by default (without -u) so streams dont preserve order
# > >(one) 2> >(two) are background processes so it will break our parallel code.
xerr() {
  fname="${FUNCNAME[1]#*.}"
  if [[ ${#fname} -gt $MAX_FNAME_LOG_LEN ]]; then
    fname="${fname:0:$MAX_FNAME_LOG_LEN}…"
  fi
  if [[ "$CMD" = "$fname" ]]; then
    cat # remove logging for the command itself
  else
    fn=$(printf "%*s |\n" $((MAX_FNAME_LOG_LEN + 1)) "$fname")
    sed -ue "s/^/${RED}$fn${OFF} /" >&2
  fi
}

# Check build dependencies are met.
x.check-build-deps() {
  { { {
    local -i fails
    check.column || { ((fails++)) && true; }
    check.protoc || { ((fails++)) && true; }
    check.bash || { ((fails++)) && true; }
    check.go || { ((fails++)) && true; }
    check.java || { ((fails++)) && true; }
    check.curl || { ((fails++)) && true; }
    check.docker || { ((fails++)) && true; }
    check.docker-compose && { ((fails++)) && true; }
    check.direnv || { ((fails++)) && true; }
    check.yq || { ((fails++)) && true; }
    check.pg_format || { ((fails++)) && true; }
    ((fails == 0)) && echo "${GREEN}🎉 All build dependencies met.${OFF}"
    { ((fails != 0)) && err "${RED}❌ Missing dependencies.${OFF}"; } || true
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Check dependencies and fetch required tools.
x.bootstrap() {
  { { {
    x.check-build-deps
    x.install-tools
    x.fetch.openapi-gen
    x.fetch.swagger-ui
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Install go libraries as runnable programs.
x.install-tools() {
  { { {
    set -o errexit -eo pipefail

    go install -tags 'postgres' github.com/golang-migrate/migrate/v4/cmd/migrate@v4.15.2
    go install github.com/kyleconroy/sqlc/cmd/sqlc@v1.15.0
    go install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.47.2
    go install github.com/joho/godotenv/cmd/godotenv@latest
    go install github.com/danicc097/air@latest
    go install github.com/xo/xo@latest
    go install github.com/tufin/oasdiff@latest
    go install golang.org/x/tools/cmd/goimports@latest
    go install mvdan.cc/gofumpt@latest

    go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.27.1
    go install github.com/planetscale/vtprotobuf/cmd/protoc-gen-go-vtproto@v0.2.0
    go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2

    GO111MODULE=off go get -u github.com/maxbrunsfeld/counterfeiter
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Fetch openapi-generator jar file.
x.fetch.openapi-gen() {
  { { {
    local url="https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/$GENVERS/openapi-generator-cli-$GENVERS.jar"
    echo "$url > openapi-generator-cli.jar"
    curl -L "$url" -o openapi-generator-cli.jar
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Fetch latest swagger ui bundle.
x.fetch.swagger-ui() {
  { { {
    name="$(curl --silent "https://api.github.com/repos/swagger-api/swagger-ui/releases/latest" | jq -r ".. .tag_name? // empty")"
    curl -fsSL "github.com/swagger-api/swagger-ui/archive/refs/tags/$name.tar.gz" -o swagger-ui.tar.gz
    tar xf swagger-ui.tar.gz swagger-ui-"${name#*v}"/dist --one-top-level=swagger-ui --strip-components=2
    rm swagger-ui.tar.gz
    mkdir -p internal/static/swagger-ui
    mv swagger-ui/* internal/static/swagger-ui/
    rm -r swagger-ui
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Run openapi generator for testdata.
# jar won't output properly if absolute paths are passed from subdir.
x.gen.tests-api() {
  { { {
    local testdata="$BIN_DIR/../internal/postgen/testdata/openapi_generator"
    local test_dirs=$(find "$testdata" -maxdepth 1 -mindepth 1 -type d -exec basename {} \;)

    cache=".generate-tests-api.cache"
    for test_dir in $test_dirs; do
      generate_api \
        "$cache" \
        "$test_dir" \
        "$testdata/$test_dir/openapi.yaml" \
        "$testdata/$test_dir/internal" \
        "$BIN_DIR/../internal/go-gin-server-templates"
    done
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Run post-generation scripts on the internal package.
x.postgen() {
  { { {
    echo "Running generation"
    cache="$1"
    mkdir -p "$cache"
    go build -o postgen "$PWD"/cmd/postgen/main.go
    ./postgen -cachedir="$cache" -env=".env.$env"
    mv "$OPENAPI_GEN_DIR"/api_*.go "$cache/" 2>/dev/null || true
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Generate type-safe Go code from SQL.
x.gen.sqlc() {
  { { {
    echo "Running generation"
    sqlc generate -f "$PG_REPO"/sqlc.yaml || err "Failed sqlc generation"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Generate mocks for specified interfaces. Runs are cached to `cachedir`.
# Args: cachedir
x.gen.counterfeiter() {
  # This shouldn't pose any problems, the interface is the only input to counterfeiter.
  { { {
    cache="$1"

    envvar="internal/envvar/envvar.go"
    services="internal/rest/services.go"
    repos="internal/services/repos.go"
    tfidfpb="internal/pb/python-ml-app-protos/tfidf/v1/service_grpc.pb.go"

    echo "Running generation"

    if ! md5sum -c "$cache/counterfeiter.md5" >/dev/null || [[ $force_regen -eq 1 ]]; then
      echo "Recreating mocks"
      {
        counterfeiter -o internal/envvar/envvartesting/provider.gen.go $envvar Provider &
        counterfeiter -o internal/rest/resttesting/authorization.gen.go $services AuthorizationService &
        counterfeiter -o internal/rest/resttesting/authentication.gen.go $services AuthenticationService &
        counterfeiter -o internal/services/servicestesting/user.gen.go $repos UserRepo &
        counterfeiter -o internal/rest/resttesting/user.gen.go $services UserService &
        counterfeiter -o internal/pb/python-ml-app-protos/tfidf/v1/v1testing/movie_genre_client.gen.go $tfidfpb MovieGenreClient &
        counterfeiter -o internal/pb/python-ml-app-protos/tfidf/v1/v1testing/movie_genre_server.gen.go $tfidfpb MovieGenreServer &
        md5sum $envvar $services $repos $tfidfpb >"$cache/counterfeiter.md5" &
        wait
      } 2>&1 # outputs to stderr for some reason

      # counterfeiter is unaware of grpc's obscure mustEmbedUnimplemented***() for forward server compatibility
      sed -i '/type FakeMovieGenreServer struct {/a v1\.UnimplementedMovieGenreServer' \
        internal/pb/python-ml-app-protos/tfidf/v1/v1testing/movie_genre_server.gen.go
    fi
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Generate the required servers/clients for relevant services.
x.gen.proto() {
  { { {
    local import_path="python-ml-app-protos/tfidf/v1"
    local filename="internal/python-ml-app-protos/tfidf/v1/service.proto"

    mkdir -p internal/pb
    # Plugins are no longer supported by protoc-gen-go.
    # Instead protoc-gen-go-grpc and the go package (in proto or via M flag) are required
    echo "Running generation"
    protoc \
      --go-grpc_out=internal/pb/. \
      --go_out=internal/pb/. \
      --go-grpc_opt=M$filename=$import_path,paths=import \
      --go_opt=M$filename=$import_path,paths=import \
      internal/python-ml-app-protos/tfidf/v1/service.proto
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Run all codegen and postgen commands for the project.
x.gen() {
  { { {
    echo "Running code generation"
    local _pids

    x.db.recreate

    cache=".generate.cache"

    generate_api "$cache" "internal" "$SPEC" "$OPENAPI_GEN_OUT_DIR" "$TEMPLATE_DIR"

    rm -rf $PG_REPO/gen

    go generate ./... &
    _pids+=($!)
    x.gen.sqlc &
    _pids+=($!)
    x.gen.proto &
    _pids+=($!)
    x.postgen "$cache" &
    _pids+=($!)

    for pid in "${_pids[@]}"; do
      wait "$pid"
    done

    (
      # xo cannot use db files as input, needs an up-to-date schema
      # not recreating db on every gen can lead to plain wrong generation based on an old dev schema
      # use a unique db to prevent cosmic accidents
      export POSTGRES_DB="xoxo"
      x.db.drop
      x.migrate up
      generate_xo || err "Failed xo generation"
    )

    # delay since it depends on generated output
    x.gen.counterfeiter "$cache"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Lint the entire project.
x.lint() {
  { { {
    x.lint.sql &
    x.lint.go &
    wait
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Format Go files.
x.lint.go() {
  { { {
    files=$(find . \
      -not -path "**/$OPENAPI_GEN_DIR/*" \
      -not -path "**/$PROTO_DIR/*" \
      -not -path "**/$PG_REPO/gen/*" \
      -not -path "**/testdata/*" \
      -not -path "**/*.cache/*" \
      -name "*.go")

    goimports -w $files
    gofumpt -w $files
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Format SQL files.
x.lint.sql() {
  { { {
    SQL_DIRS=(
      "$PG_REPO/queries"
      "db"
    )
    for slq_dir in ${SQL_DIRS[@]}; do
      pg_format \
        --spaces 2 \
        --wrap-limit 88 \
        --function-case 2 \
        --keyword-case 1 \
        --placeholder "sqlc\\.(arg|narg)\\(:?[^)]*\\)" \
        --inplace \
        $(find "$slq_dir" -maxdepth 3 -name '*.sql')
    done
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Run required backend pre-test setup: services, database cleanup, codegen...
# Can be called independently, e.g. before running tests through an IDE.
x.test.backend-setup() {
  { { {
    # NOTE: tests run independently in Go so we can't have a function be called and run
    # only once before any test starts
    run_shared_services up -d --remove-orphans
    x.gen
    drop_and_recreate_db "postgres_test"
    x.gen.tests-api
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Test the entire project. Accepts `go test` parameters.
# Args: [...]
x.test() {
  { { {
    x.test.backend-setup
    APP_ENV="$env" go test "$@" ./...
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Test and build the entire project.
x.build() {
  { { {
    x.lint
    x.test ""
    go build -o rest-server "$PWD"/cmd/rest-server
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Run backend with hot-reloading.
x.run.backend-hr() {
  run_shared_services up -d --remove-orphans
  # TODO new include_files flag in fork, e.g. for openapi.yaml.
  # else generated .yaml files trigger rebuild.
  # --build.include_files "openapi.yaml" \
  # NOTE: building binary very unreliable, leads to bin not found.
  air \
    --build.pre_build_cmd "bin/project generate" \
    --build.cmd "" \
    --build.bin "go run ./cmd/rest-server/ -env=.env.$env" \
    --build.include_ext "go" \
    --build.exclude_regex ".gen.go,_test.go" \
    --build.exclude_dir ".git,tmp,$OPENAPI_GEN_DIR,$PROTO_DIR,$PG_REPO/gen,**/testdata,frontend,*.cache" \
    --build.stop_watch "internal/rest/,internal/services/" \
    --build.delay 1000 \
    --build.exclude_unchanged "true" |
    sed -e "s/^/${BLUE}[Air]${OFF} /"
}

# Run frontend with hot-reloading.
x.run.frontend() {
  set -a
  # export to replace config with envvars
  source ".env.$env"
  set +a

  cd frontend
  pnpm run generate

  pnpm run dev |
    sed -e "s/^/${GREEN}[Vite]${OFF} /"
}

# Run all project services with hot reload enabled in dev mode.
x.run-dev() {
  env="dev"

  run_hot_reload

  next_allowed_run=$(date +%s)
  latency=3
  # close_write event, else duplicated, tripl. events -> race condition
  while true; do
    inotifywait \
      --monitor "$SPEC" \
      --event=close_write \
      --format='%T %f' \
      --timefmt='%s' |
      while read -r event_time event_file 2>/dev/null || sleep $latency; do
        if [[ $event_time -ge $next_allowed_run ]]; then
          next_allowed_run=$(date --date="${latency}sec" +%s)

          for pid in "${pids[@]}"; do
            # air and vite spawn processes as well, need to kill those (whose parent is pid), kill $pid will not kill children. pkill -P would also work
            kill $(list_descendants $pid)
          done
          pids=()

          run_hot_reload
        fi
      done
  done
}

# Run project in production mode.
x.run-prod() {
  env="prod"

  docker network create traefik-net 2>/dev/null || true
  run_shared_services up -d --remove-orphans
  x.db.recreate

  cd frontend && pnpm run generate && cd - >/dev/null
  x.gen

  DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain docker-compose \
    --project-name "$PROJECT_PREFIX"_"$env" \
    -f docker-compose."$env".yml \
    --env-file ".env.$env" \
    up -d --build 2>&1 # https://github.com/docker/compose/issues/7346

  # TODO handle rollback and restore up to X revision (from restored db)
  # see dump_schema_v
  echo "Migrations:"
  x.migrate up
}

# Remove running project containers, including shared ones between environments.
x.stop-project() {
  { { {
    run_shared_services down --remove-orphans
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Checks before release:
# - Magic keyword "STOPSHIP" not found in tracked files.
x.release() {
  { { {
    x.search-stopship "STOPSHIP" &
    pids+=($!)
    go mod verify &
    pids+=($!)

    for pid in "${pids[@]}"; do
      wait "$pid"
    done
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Block build if magic keyword is found in any file
# Args: keyword
x.search-stopship() {
  { { {
    stopship_keyword="$1"
    local matches
    matches=$(find "$(git rev-parse --show-toplevel)" \
      -type f \
      -not -path '**/.git/*' \
      -not -path '**/.venv/*' \
      -not -path '**/node_modules/*' \
      -not -path '**/build/*' \
      -not -path '**/*.pyc' \
      -not -path "$0" \
      -not -exec git check-ignore -q --no-index {} \; \
      -exec grep -i --files-with-matches --regexp="$stopship_keyword" {} \;)
    if [[ -n $matches ]]; then
      echo "${RED}'$stopship_keyword'${OFF} found in tracked files."
      echo "Please fix all related issues in the following files:"
      printf "\t %s\n" $matches
      exit 1
    fi
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

########################## migrations ##########################

# Wrapper for golang-migrate with predefined configuration.
x.migrate() {
  { { {
    migrate \
      -path db/migrations/ \
      -database "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable" \
      "$@" 2>&1 # migrate outputs everything to stderr

    if [[ "${*:1}" =~ up* ]]; then
      echo "Running post-migration scripts"
      for file in $(find db/post-migration -maxdepth 1 -name '*.sql' | sort); do
        dockerdb psql --no-psqlrc -tA -U postgres -d "$POSTGRES_DB" <$file
      done
    fi
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Create a new migration file with the given `name`.
# Args: name
x.migrate.create() {
  { { {
    tmp="$*"
    tmp="${tmp// /_}"
    name="${tmp,,}"
    [[ -z $name ]] && err "Please provide a migration name"
    x.migrate create -ext sql -dir db/migrations/ -seq -digits 7 "$name"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

########################## db ##########################

# Shows active and max number of connections for the current environment.
x.db.conns() {
  { { {
    current_conns=$(dockerdb psql -qtAX -d $POSTGRES_DB -c "SELECT count(*) FROM pg_stat_activity WHERE datname = '$POSTGRES_DB';")
    max_conns=$(dockerdb psql -qtAX -d $POSTGRES_DB -c "SHOW max_connections;")
    echo "$current_conns/$max_conns active connections in '$POSTGRES_DB'"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Create a new database in the current environment if it doesn't exist
# and stops its running processes if any.
x.db.recreate() {
  { { {
    create_db_if_not_exists "postgres_$env"
    stop_db_processes "postgres_$env"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Drop and recreate the database in the current environment.
x.db.drop() {
  { { {
    drop_and_recreate_db "$POSTGRES_DB"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Backup the database for the current environment.
x.db.dump() {
  { { {
    running_dumps=$(dockerdb psql --no-psqlrc -P pager=off --quiet -tA -U postgres -d "postgres_$env" \
      -c "SELECT pid FROM pg_stat_activity WHERE application_name = 'pg_dump';")
    if [[ "$running_dumps" != "" ]]; then
      err "pg_dump is already running, aborting new dump"
    fi

    mkdir -p "$DUMPS_FOLDER"
    schema_v=$(dockerdb psql --no-psqlrc -P pager=off --quiet -tA -U postgres -d "postgres_$env" \
      -c "SELECT version FROM schema_migrations;")
    dump_file="${dump_prefix}$(date +%Y-%m-%dT%H-%M-%S)_version${schema_v}.gz"

    echo "Dumping database to $dump_file"
    docker exec -i postgres_db_"$PROJECT_PREFIX" pg_dump -U postgres -d "postgres_$env" |
      gzip >"$DUMPS_FOLDER/$dump_file"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Restore the database with the latest dump or `file` for the current environment.
# Args: [file]
x.db.restore() {
  { { {
    dump_file="$1"
    if [[ -n $dump_file ]]; then
      [[ ! -f $dump_file ]] && err "$dump_file does not exist"
      [[ "$dump_file" != *"$dump_prefix"* ]] && confirm "${RED}Dump doesn't match prefix '$dump_prefix'. Continue?${OFF}"
    else
      mkdir -p "$DUMPS_FOLDER"
      latest_dump_file=$(find "$DUMPS_FOLDER"/ -name "$dump_prefix*.gz" | sort -r | head -n 1)
      if [[ -z "$latest_dump_file" ]]; then
        err "No $dump_prefix* file found in $DUMPS_FOLDER"
      fi
      dump_file="$latest_dump_file"
    fi

    confirm "Do you want to restore ${YELLOW}$dump_file${OFF} in the ${RED}$env${OFF} environment?"

    x.db.drop
    gunzip -c "$dump_file" | dockerdb psql --no-psqlrc -U postgres -d "postgres_$env"
    # sanity check, but probably better to do it before restoring...
    dump_schema_v=$(dockerdb psql --no-psqlrc -P pager=off -qtAX -U postgres -d "postgres_$env" -c "SELECT version FROM schema_migrations;")
    file_schema_v=$(echo "$dump_file" | sed -E 's/.*_version([0-9]+)\..*/\1/')
    echo "Migration revision: $dump_schema_v"
    if [[ "$dump_schema_v" != "$file_schema_v" ]]; then
      err "Schema version mismatch: dump $dump_schema_v != file $file_schema_v"
    fi
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

########################## e2e ##########################

# Setup E2E Python environment.
x.e2e.sync-deps() {
  { { {
    cd e2e
    python -m venv .venv
    source .venv/bin/activate
    pip install pip-tools
    pip-compile requirements.in
    pip-compile requirements-dev.in
    pip-sync requirements-dev.txt requirements.txt
    cd - >/dev/null
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Run E2E tests. Accepts `pytest` parameters.
# Args: [...]
x.e2e.run() {
  { { {
    name="$PROJECT_PREFIX-e2e"
    cd e2e
    DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain \
      docker build -t "$name" .
    docker run -it --rm --ipc=host -v "$(pwd):/src" "$name" bash -c "pytest $*"
    cd - >/dev/null
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

########################## openapi ##########################

# Validates the project's OpenAPI specification or `spec`.
# Args: [spec]
x.validate() {
  # quite unreliable. e.g. ignored examples inexistent ref.
  # prefer built in kin-openapi validation
  java -jar openapi-generator-cli.jar validate -i "${1:-$SPEC}"
}

# Wrapper for openapi-generator with sane output modifications.
# Args: spec out tpl
x.openapi-generator() {
  { { {
    local spec="$1"
    local gen_out_dir="$2"
    local template_dir="$3"

    [[ -z $spec ]] && err "openapi-generator: spec required"
    [[ -z $gen_out_dir ]] && err "openapi-generator: out dir required"
    [[ -z $template_dir ]] && err "openapi-generator: template dir required"
    echo "Generating API from $spec"
    echo "Generation directory: $gen_out_dir"
    echo "Template override directory: $template_dir"

    rm -rf "$gen_out_dir/gen"
    # debug has a very small overhead compared to the >1s required per spec
    java -jar "$BIN_DIR"/../openapi-generator-cli.jar generate \
      -g go-gin-server \
      -i "$spec" \
      -o "$gen_out_dir" \
      -t "$template_dir" \
      --additional-properties=packageName=openapi,apiPath=gen,hideGenerationTimestamp=true \
      --enable-post-process-file \
      --global-property=debugModels,debugOperations >debug-openapi.log #>/dev/null \

    mkdir -p "$gen_out_dir"/gen/models
    mkdir -p "$gen_out_dir"/rest
    mkdir -p "$gen_out_dir"/services

    mv "$gen_out_dir"/gen/routers.go "$gen_out_dir"/rest/routers.gen.go

    {
      mv "$gen_out_dir"/gen/model_*.go "$gen_out_dir"/gen/models 2>/dev/null
      goimports -w "$gen_out_dir"/gen/models
    } || echo "No model files found. Skipping"

    rm -rf "$gen_out_dir/api"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

# Run a diff against the previous OpenAPI spec in the main branch.
# Can also be used to generate changelogs when upgrading major versions.
x.diff-oas() {
  { { {
    base_spec="/tmp/openapi.yaml"
    git show "main:$SPEC" >"$base_spec"

    tmp="$(yq .info.version "$base_spec")"
    base_v="${tmp%%.*}"
    tmp=$(yq .info.version "$SPEC")
    rev_v="${tmp%%.*}"
    ((rev_v != base_v)) &&
      echo "${YELLOW}Revision mismatch $rev_v and $base_v, skipping diff.${OFF}" && return

    args="-format text -breaking-only -fail-on-diff -exclude-description -exclude-examples"
    if oasdiff $args -base "$base_spec" -revision $SPEC; then
      echo "${GREEN}No breaking changes found in $SPEC${OFF}"
    else
      echo "${RED}Breaking changes found in $SPEC${OFF}"
      return 1
    fi
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

########################### helpers ###########################

# IMPORTANT: bug in declare -F returns line number of last nested function, if any.
# extracting function here instead...
run_hot_reload() {
  x.run.backend-hr &
  pids+=("$!")
  x.run.frontend &
  pids+=("$!")
}

run_shared_services() {
  cd docker
  docker-compose \
    -p "$PROJECT_PREFIX" \
    -f docker-compose.shared.yml \
    --env-file ../.env."$env" \
    "$@" 2>&1 # https://github.com/docker/compose/issues/7346
  cd - >/dev/null
}

# Automatically generate CRUD and By queries based on existing indexes from a Postgres schema.
generate_xo() {
  # TODO from hn
  # I've used https://github.com/xo/xo, extended it with some custom functions for templating, extended the templates themselves, and can now generate CRUD for anything in the database, functions for common select queries based on the indices that exist in the database, field filtering and scanning, updates for subsets of fields including some atomic operations, etc. The sky is the limit honestly. It has allowed me to start with something approximating a statically generated ORM and extend it with any features I want as time goes on. I also write .extra.go files along side the generated .xo.go files to extend the structs that are generated with custom logic and methods to convert data into response formats.

  { { {
    echo "Running generation"

    echo $PG_REPO

    mkdir -p $PG_REPO/gen/db
    # xo schema --help
    # xo schema "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable"       --src="$PG_REPO/xo-templates" -o "$PG_REPO"/gen/db -e "*.created_at" -e "*.updated_at" # --go-custom="db" \
    echo "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable"
    xo schema "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable" \
      --src "$PG_REPO"/xo-templates \
      -o "$PG_REPO"/gen/db \
      -e "*.created_at" \
      -e "*.updated_at"
  } 2>&4 | xlog >&3; } 4>&1 | xerr >&3; } 3>&1
}

generate_api() {
  cache="$1"
  prefix="$2"
  spec="$3"
  gen_out_dir="$4"
  template_dir="$5"

  invalid_cache=false

  if [[ $force_regen -eq 1 ]]; then
    rm -rf "$cache"
  fi

  mkdir -p "$cache"

  if ! md5sum -c "$cache/$prefix-go-gin-server-templates.md5" >/dev/null; then
    invalid_cache=true
    md5sum "$BIN_DIR"/../internal/go-gin-server-templates/* >"$cache/$prefix-go-gin-server-templates.md5"
  fi
  if ! md5sum -c "$cache/$prefix-openapi.md5" >/dev/null; then
    invalid_cache=true
    md5sum "$BIN_DIR"/../"$SPEC" >"$cache/$prefix-openapi.md5"
  fi

  if [[ $invalid_cache == true ]]; then
    x.openapi-generator \
      "$spec" \
      "$gen_out_dir" \
      "$template_dir"
  fi
}

usage() {
  command_comments_parser() {
    head -$((${lns[$i]} - 1)) $0 |
      tac |
      sed -n '/#/!q;p' |
      tac |
      awk '{$1=$1;print}'
  }

  command_options_comments_parser() {
    tail -n +$((${lns[$i]} + 1)) $0 |
      sed -n '/^[[:blank:]]*#/!q;p' |
      awk '{$1=$1;print}'
  }

  construct_column() {
    comment_parser="$1"
    for i in ${!lns[@]}; do
      comment_paragraph="$($comment_parser)"
      ROWS["${rows[$i]}"]="$comment_paragraph"
      mapfile -t comments <<<"${ROWS[${rows[$i]}]}"
      for comment in "${comments[@]}"; do
        comment="$(clean_comment "$comment")"
        args="-"
        if [[ ${comment,,} == args:* ]]; then
          args=$(clean_args "$comment")
        fi
        ROW_ARGS[${rows[$i]}]="$args"
      done
    done

    for i in "${!rows[@]}"; do
      mapfile -t comments <<<"${ROWS[${rows[$i]}]}"
      for j in "${!comments[@]}"; do
        comment="$(clean_comment "${comments[$j]}")"
        if [[ ${comment,,} == args:* ]]; then
          continue
        fi

        if [[ $j = 0 ]]; then
          docs+=("$(
            printf -- "%s\t%s\t%s" \
              "${rows[$i]}" \
              "${ROW_ARGS[${rows[$i]}]}" \
              "$comment"
          )")
          continue
        fi

        docs+=("$(
          printf -- "%s\t%s\t%s" \
            "" \
            "" \
            "$comment"
        )")
      done
    done

    column -t \
      --separator $'\t' \
      --output-width 150 \
      --table-noextreme C2 \
      --table-noheadings \
      --table-wrap C3 \
      --table-columns C1,C2,C3 < <(printf "    %s\n" "${docs[@]}")
  }

  declare -A ROWS ROW_ARGS
  declare docs rows X_OPTIONS

  for c in "${COMMANDS[@]}"; do
    shopt -s extdebug
    lns+=("$(declare -F x.$c | awk '{print $2}')")
    rows+=("${c}")
    shopt -u extdebug
  done

  x_functions="$(construct_column command_comments_parser)"

  lns=()
  rows=()
  docs=()

  parse_x_options X_OPTIONS

  for c in "${X_OPTIONS[@]}"; do
    lns+=("${c##*)}")
    rows+=("${c%%)*}")
  done

  x_options="$(construct_column command_options_comments_parser)"

  cat <<EOF

$BOLD$UNDERSCORE$(basename $0)$OFF centralizes all relevant project commands.

${BOLD}USAGE:
    $RED$(basename $0) x.function [--x-option ...] args [optional args]$OFF

${BOLD}x.functions:$OFF
$(echo "${x_functions}" |
    sed -E 's/    ([[:alnum:][:punct:]]*)(.*)/    '"$BLUE$BOLD"'\1'"$OFF"'\2''/')

${BOLD}--x-options:$OFF
$(echo "${x_options}" |
      sed -E 's/    ([[:alnum:][:punct:]]*)(.*)/    '"$GREEN$BOLD"'\1'"$OFF"'\2''/')
EOF

}

# gets all --x-options values
parse_x_options() {
  declare -n list="$1" # pass ref by name
  while IFS= read -r line; do
    list+=("$(awk '{$1=$1;print $1 $NF}' <<<"$line")")
  done < <(sed -nr '/.*(--x-[=*[:alnum:]_-]+[)]+).*/{p;=}' $0 | sed '{N;s/\n/ /}')
  mapfile -t list < \
    <(LC_COLLATE=C sort < <(printf "%s\n" "${list[@]}"))
}

clean_comment() {
  tmp="$1"
  tmp="${tmp//\#/}"
  comment="${tmp#* }"
  [[ -z $comment ]] && comment="·"
  # TODO split in % MAX_COMMENT_LEN lines instead, on spaces only.
  ((${#comment} > MAX_COMMENT_LEN)) && comment="${comment:0:MAX_COMMENT_LEN}..."
  echo "$comment"
}

clean_args() {
  tmp="$1"
  tmp="${tmp,,##*args\:}"
  args="${tmp#* }"
  echo "$args"
}

# --------------------- completion and delegation --------------------
#      `complete -C foo foo` > `source <(foo bloated_completion)`

while IFS= read -r line; do
  [[ $line =~ ^declare\ -f\ x\. ]] || continue
  COMMANDS+=("${line##declare -f x.}")
done < <(declare -F)
# sort the array. Mimic file input to sort
mapfile -t COMMANDS < \
  <(LC_COLLATE=C sort < <(printf "%s\n" "${COMMANDS[@]}"))

MAX_XFN_LEN=0 # for logging purposes
for c in "${COMMANDS[@]}"; do
  len=${#c}
  ((len > MAX_XFN_LEN)) && MAX_XFN_LEN=$((len - 1)) # remove "x." but account for extra last space appended.
done

if [[ -n $COMP_LINE ]]; then
  pre="${COMP_LINE##* }" # the part after the last space in the current command
  cur_commands=(${COMP_LINE%"$pre"})

  for c in "${COMMANDS[@]}"; do
    if [[ " ${cur_commands[*]} " =~ " ${c} " ]]; then
      xfn_specified=true
      break
    fi
  done

  for c in "${COMMANDS[@]}"; do
    test -z "${xfn_specified}" || break
    test -z "${pre}" -o "${c}" != "${c#"${pre}"}" -a "${pre}" != "${c}" && echo "${c}"
  done

  test -z "${xfn_specified}" && exit

  declare __x_options x_options_lines

  parse_x_options x_options_lines

  for c in "${x_options_lines[@]}"; do
    tmp="${c%%)*}"
    xopt="${tmp//\*/}"
    __x_options+=("$xopt")
  done

  declare -A __x_opts_seen
  for cmd in "${cur_commands[@]}"; do
    for opt in ${__x_options[@]}; do
      if [[ "$cmd" == *"$opt"* ]]; then
        __x_opts_seen[$opt]=true
        break
      fi
    done
  done

  for opt in ${__x_options[@]}; do
    [[ -n "${__x_opts_seen[$opt]}" ]] && continue
    # TODO prevent opts that accept values having whitespace added
    [[ ${opt:0:${#pre}} == "${pre,,}" ]] && echo "${opt}"
  done

  exit
fi

# First comment lines automatically added to usage docs.
set +e
while [[ "$#" -gt 0 ]]; do
  case $1 in
  --x-force-regen) # this comment should be ignored
    # Removes generation cache, forcing a new run.
    force_regen=1
    ;;
  --x-no-confirmation)
    # Bypasses confirmation messages.
    export NO_CONFIRMATION=1
    ;;
  --x-env=*)
    # Environment to run commands in. Defaults to "dev".
    # Args: env
    env="${1#--x-env=}"
    valid_envs="dev staging prod ci"
    if [[ ! " ${valid_envs[*]} " =~ " $env " ]]; then
      err "Valid environments: $valid_envs"
    fi
    ;;
  *)
    # will set everything else back
    args+=("$1")
    ;;
  esac
  shift
done
set -e
for arg in ${args[@]}; do
  set -- "$@" "$arg"
done
# applicable to any command
ensure_envvars_set ".env.template" ".env.${env}"
source ".env.$env"

# handle executing x functions
if [[ -n "$1" ]]; then
  declare CMD="$1"
  shift
  for c in "${COMMANDS[@]}"; do
    declare cmd=$(command -v "x.$c")
    if [[ $c == "$CMD" && -n "$cmd" ]]; then
      "x.$CMD" "$@"
      exit $?
    fi
  done
fi

# default to show usage if its a noop
usage
