#!/bin/bash
# shellcheck disable=1091,2155,2068,2086

source "${BASH_SOURCE%/*}/.helpers.sh"
source "${BASH_SOURCE%/*}/scripts/deps-check.sh"

set -Eeo pipefail

trap killgroup SIGINT

pids=()
killgroup() {
  printf "\nkilling spawned processes...\n"
  kill 0
}

ensure_pwd_is_top_level
source ".envrc"

export GIT_USER_ID=danicc097
export GIT_REPO_ID=openapi-go-gin-postgres-sqlc
export GO_POST_PROCESS_FILE="/usr/bin/env gofmt -w -s"
export GENVERS=6.0.1

SPEC="openapi.yaml"
OPENAPI_GEN_OUT_DIR="internal"
OPENAPI_GEN_DIR="$OPENAPI_GEN_OUT_DIR/gen"
PROTO_DIR="internal/pb"
TEMPLATE_DIR="internal/go-gin-server-templates"
PWD="$(pwd)"
env="dev"
BIN_DIR=$(dirname "${BASH_SOURCE[0]}")
PG_REPO="internal/repos/postgresql"

DUMPS_FOLDER="$HOME/openapi_go_gin_postgres_dumps"
DUMP_PREFIX="dump_${env}_"

MAX_COMMENT_LEN=88

# Check build dependencies are met.
x.check-build-deps() {
  local -i fails
  check.column || { ((fails++)) && true; }
  check.protoc || { ((fails++)) && true; }
  check.bash || { ((fails++)) && true; }
  check.go || { ((fails++)) && true; }
  check.java || { ((fails++)) && true; }
  check.curl || { ((fails++)) && true; }
  check.docker || { ((fails++)) && true; }
  check.docker-compose || { ((fails++)) && true; }
  check.direnv || { ((fails++)) && true; }
  check.yq || { ((fails++)) && true; }
  check.pg_format || { ((fails++)) && true; }
  ((fails == 0)) && echo "${GREEN}🎉 All build dependencies met.${OFF}"
  { ((fails != 0)) && err "${RED}❌ Missing dependencies.${OFF}"; } || true
}

# Check dependencies and fetch required tools.
x.bootstrap() {
  x.check-build-deps
  x.install-tools
  x.fetch.openapi-generator
  x.fetch.swagger-ui
}

# Install go libraries as runnable programs.
x.install-tools() {
  set -o errexit -eo pipefail

  go install -tags 'postgres' github.com/golang-migrate/migrate/v4/cmd/migrate@v4.15.2
  go install github.com/kyleconroy/sqlc/cmd/sqlc@v1.15.0
  go install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.47.2
  go install github.com/joho/godotenv/cmd/godotenv@latest
  go install github.com/danicc097/air@latest
  go install github.com/xo/xo@latest
  go install github.com/tufin/oasdiff@latest
  go install golang.org/x/tools/cmd/goimports@latest
  go install mvdan.cc/gofumpt@latest

  go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.27.1
  go install github.com/planetscale/vtprotobuf/cmd/protoc-gen-go-vtproto@v0.2.0
  go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2

  GO111MODULE=off go get -u github.com/maxbrunsfeld/counterfeiter
}

# Fetch openapi-generator jar file.
x.fetch.openapi-generator() {
  local url="https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/$GENVERS/openapi-generator-cli-$GENVERS.jar"
  echo "$url > openapi-generator-cli.jar"
  curl -L "$url" -o openapi-generator-cli.jar
}

# Fetch latest swagger ui bundle.
x.fetch.swagger-ui() {
  name="$(curl --silent "https://api.github.com/repos/swagger-api/swagger-ui/releases/latest" | jq -r ".. .tag_name? // empty")"
  curl -fsSL "github.com/swagger-api/swagger-ui/archive/refs/tags/$name.tar.gz" -o swagger-ui.tar.gz
  tar xf swagger-ui.tar.gz swagger-ui-"${name#*v}"/dist --one-top-level=swagger-ui --strip-components=2
  rm swagger-ui.tar.gz
  mkdir -p internal/static/swagger-ui
  mv swagger-ui/* internal/static/swagger-ui/
  rm -r swagger-ui
}

# Run openapi generator for testdata.
# jar won't output properly if absolute paths are passed from subdir.
x.generate.tests-api() {
  local testdata="$BIN_DIR/../internal/postgen/testdata/openapi_generator"
  local test_dirs=$(find "$testdata" -maxdepth 1 -mindepth 1 -type d -exec basename {} \;)

  cache=".generate-tests-api.cache"
  for test_dir in $test_dirs; do
    generate_api \
      "$cache" \
      "$test_dir" \
      "$testdata/$test_dir/openapi.yaml" \
      "$testdata/$test_dir/internal" \
      "$BIN_DIR/../internal/go-gin-server-templates"
  done
}

# Run post-generation scripts on the internal package.
x.postgen() {
  cache="$1"
  mkdir -p "$cache"
  go build -o postgen "$PWD"/cmd/postgen/main.go
  ./postgen -cachedir="$cache" -env=".env.$env"
  mv "$OPENAPI_GEN_DIR"/api_*.go "$cache/" 2>/dev/null || true
}

# Generate type-safe Go code from SQL.
x.generate.sqlc() {
  { cd $PG_REPO && sqlc generate && cd - >/dev/null; } || err "Failed sqlc generation"
}

# Automatically generate CRUD and By queries based on existing indexes from
# a Postgres schema.
# Does not work with a schema file, database must be up to date.
x.generate.xo() {
  # TODO
  # I've used https://github.com/xo/xo, extended it with some custom functions for templating, extended the templates themselves, and can now generate CRUD for anything in the database, functions for common select queries based on the indices that exist in the database, field filtering and scanning, updates for subsets of fields including some atomic operations, etc. The sky is the limit honestly. It has allowed me to start with something approximating a statically generated ORM and extend it with any features I want as time goes on. I also write .extra.go files along side the generated .xo.go files to extend the structs that are generated with custom logic and methods to convert data into response formats.

  rm -rf $PG_REPO/gen/crud
  mkdir -p $PG_REPO/gen/crud
  # xo schema --help
  xo schema "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable" \
    --src "$PG_REPO"/xo-templates \
    -o "$PG_REPO"/gen/crud \
    -e "*.created_at" \
    -e "*.updated_at"

}

# Generate mocks for specified interfaces. Runs are cached to `cachedir`.
# Args: cachedir
x.generate.counterfeiter() {
  # This shouldn't pose any problems, the interface is the only input to counterfeiter.
  cache="$1"

  envvar="internal/envvar/envvar.go"
  services="internal/rest/services.go"
  repos="internal/services/repos.go"

  if ! md5sum -c "$cache/counterfeiter.md5" >/dev/null || [[ $force_regen -eq 1 ]]; then
    counterfeiter -o internal/envvar/envvartesting/provider.gen.go $envvar Provider &
    counterfeiter -o internal/rest/resttesting/authorization.gen.go $services AuthorizationService &
    counterfeiter -o internal/rest/resttesting/authentication.gen.go $services AuthenticationService &
    counterfeiter -o internal/services/servicestesting/user.gen.go $repos UserRepo &
    md5sum $envvar $services $repos >"$cache/counterfeiter.md5" &
    wait
  fi
}

# Generate the required servers/clients for relevant services.
x.generate.proto() {
  local import_path="./python-ml-app-protos/tfidf/v1"
  local filename="python-ml-app-protos/tfidf/v1/service.proto"

  cd internal
  rm -rf ./pb
  mkdir -p ./pb
  # Plugins are no longer supported by protoc-gen-go.
  # Instead protoc-gen-go-grpc and the go package (in proto or via M flag) are required
  protoc \
    --go-grpc_out=./pb/. \
    --go_out=./pb/. \
    --go-grpc_opt=M$filename=$import_path,paths=import \
    --go_opt=M$filename=$import_path,paths=import \
    python-ml-app-protos/tfidf/v1/service.proto
  cd - >/dev/null
}

# Run all codegen and postgen commands for the project.
x.generate() {
  local pids

  x.db.recreate-database

  # need up-to-date schema for xo
  if [[ $env =~ (dev|ci) ]]; then
    x.migrate up
  fi

  echo "${MAGENTA}${BOLD}Running codegen and postgen...${OFF}"
  cache=".generate.cache"

  generate_api "$cache" "internal" "$SPEC" "$OPENAPI_GEN_OUT_DIR" "$TEMPLATE_DIR"

  go generate ./... &
  pids+=($!)
  x.generate.counterfeiter "$cache" &
  pids+=($!)
  x.generate.sqlc &
  pids+=($!)
  x.generate.xo &
  pids+=($!)
  x.generate.proto &
  pids+=($!)
  x.postgen "$cache" &
  pids+=($!)

  for pid in "${pids[@]}"; do
    wait "$pid"
  done

}

# Lint the entire project.
x.lint() {
  x.lint.sql &
  x.lint.go &
  wait
}

# Format Go files.
x.lint.go() {
  files=$(find . \
    -not -path "**/$OPENAPI_GEN_DIR/*" \
    -not -path "**/$PROTO_DIR/*" \
    -not -path "**/$PG_REPO/gen/*" \
    -not -path "**/testdata/*" \
    -not -path "**/*.cache/*" \
    -name "*.go")

  goimports -w $files
  gofumpt -w $files
}

# Format SQL files.
x.lint.sql() {
  SQL_DIRS=(
    "$PG_REPO/queries"
    "db"
  )
  for slq_dir in ${SQL_DIRS[@]}; do
    pg_format \
      --spaces 2 \
      --wrap-limit 88 \
      --function-case 2 \
      --keyword-case 1 \
      --placeholder "sqlc\\.(arg|narg)\\(:?[^)]*\\)" \
      --inplace \
      $(find "$slq_dir" -maxdepth 3 -name '*.sql')
  done
}

# Run required backend pre-test setup: services, database cleanup, codegen...
# Can be called independently, e.g. before running tests through an IDE.
x.test.backend-setup() {
  # NOTE: tests run independently in Go so we can't have a function be called and run
  # only once before any test starts
  run_shared_services up -d --remove-orphans
  x.generate
  drop_and_recreate_db "postgres_test"
  x.generate.tests-api
}

# Test the entire project. Accepts `go test` parameters.
# Args: [...]
x.test() {
  x.test.backend-setup
  APP_ENV="$env" go test "$@" ./...
}

# Test and build the entire project.
x.build() {
  x.lint
  x.test ""
  go build -o rest-server "$PWD"/cmd/rest-server
}

# Run backend with hot-reloading.
x.run.backend-hot-reload() {
  run_shared_services up -d --remove-orphans
  # TODO new include_files flag in fork, e.g. for openapi.yaml.
  # else generated .yaml files trigger rebuild.
  # --build.include_files "openapi.yaml" \
  # NOTE: building binary very unreliable, leads to bin not found.
  air \
    --build.pre_build_cmd "bin/project generate" \
    --build.cmd "" \
    --build.bin "go run ./cmd/rest-server/ -env=.env.$env" \
    --build.include_ext "go" \
    --build.exclude_regex ".gen.go,_test.go" \
    --build.exclude_dir ".git,tmp,$OPENAPI_GEN_DIR,$PROTO_DIR,$PG_REPO/gen,**/testdata,frontend,*.cache" \
    --build.stop_watch "internal/rest/,internal/services/" \
    --build.delay 1000 \
    --build.exclude_unchanged "true" |
    sed -e "s/^/${BLUE}[Air]${OFF} /"
}

# Run frontend with hot-reloading.
x.run.frontend() {
  set -a
  # export to replace config with envvars
  source ".env.$env"
  set +a

  cd frontend
  pnpm run generate

  pnpm run dev |
    sed -e "s/^/${GREEN}[Vite]${OFF} /"
}

# Run all project services with hot reload enabled in dev mode.
x.run-dev() {
  env="dev"

  run_hot_reload

  next_allowed_run=$(date +%s)
  latency=3
  # close_write event, else duplicated, tripl. events -> race condition
  while true; do
    inotifywait \
      --monitor "$SPEC" \
      --event=close_write \
      --format='%T %f' \
      --timefmt='%s' |
      while read -r event_time event_file 2>/dev/null || sleep $latency; do
        if [[ $event_time -ge $next_allowed_run ]]; then
          next_allowed_run=$(date --date="${latency}sec" +%s)

          for pid in "${pids[@]}"; do
            # air and vite spawn processes as well, need to kill those (whose parent is pid), kill $pid will not kill children. pkill -P would also work
            kill $(list_descendants $pid)
          done
          pids=()

          run_hot_reload
        fi
      done
  done
}

# Run project in production mode.
x.run-prod() {
  env="prod"

  docker network create traefik-net 2>/dev/null || true
  run_shared_services up -d --remove-orphans
  x.db.recreate-database

  cd frontend && pnpm run generate && cd - >/dev/null
  x.generate

  DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain docker-compose \
    --project-name "$PROJECT_PREFIX"_"$env" \
    -f docker-compose."$env".yml \
    --env-file ".env.$env" \
    up -d --build

  # TODO handle rollback and restore up to X revision (from restored db)
  # see dump_schema_v
  echo "Migrations:"
  x.migrate up
}

# Remove running project containers, including shared ones between environments.
x.stop-project() {
  run_shared_services down --remove-orphans
}

# Checks before release:
# - Magic keyword "STOPSHIP" not found in tracked files.
x.release() {
  x.search-stopship "STOPSHIP" &
  pids+=($!)
  go mod verify &
  pids+=($!)

  for pid in "${pids[@]}"; do
    wait "$pid"
  done
}

# Block build if magic keyword is found in any file
# Args: keyword
x.search-stopship() {
  stopship_keyword="$1"
  local matches
  matches=$(find "$(git rev-parse --show-toplevel)" \
    -type f \
    -not -path '**/.git/*' \
    -not -path '**/.venv/*' \
    -not -path '**/node_modules/*' \
    -not -path '**/build/*' \
    -not -path '**/*.pyc' \
    -not -path "$0" \
    -not -exec git check-ignore -q --no-index {} \; \
    -exec grep -i --files-with-matches --regexp="$stopship_keyword" {} \;)
  if [[ -n $matches ]]; then
    echo "${RED}'$stopship_keyword'${OFF} found in tracked files."
    echo "Please fix all related issues in the following files:"
    printf "\t %s\n" $matches
    exit 1
  fi
}

########################## migrations ##########################

# Wrapper for golang-migrate with predefined configuration.
x.migrate() {
  migrate \
    -path db/migrations/ \
    -database "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable" \
    "$@"

  if [[ "${*:1}" =~ up* ]]; then
    for file in $(find db/post-migration -maxdepth 1 -name '*.sql' | sort); do
      dockerdb psql --no-psqlrc -tA -U postgres -d "postgres_$env" <$file
    done
  fi
}

# Create a new migration file with the given `name`.
# Args: name
x.migrate.create-migration() {
  tmp="$*"
  tmp="${tmp// /_}"
  name="${tmp,,}"
  [[ -z $name ]] && err "Please provide a migration name"
  x.migrate create -ext sql -dir db/migrations/ "$name"
}

########################## db ##########################

# Create a new database in the current environment if it doesn't exist
# and stops its running processes if any.
x.db.recreate-database() {
  create_db_if_not_exists "postgres_$env"
  stop_db_processes "postgres_$env"
}

# Backup the database for the current environment.
x.db.dump() {
  running_dumps=$(dockerdb psql --no-psqlrc -P pager=off --quiet -tA -U postgres -d "postgres_$env" \
    -c "SELECT pid FROM pg_stat_activity WHERE application_name = 'pg_dump';")
  if [[ "$running_dumps" != "" ]]; then
    echo "pg_dump is already running, aborting new dump"
    exit 1
  fi

  mkdir -p "$DUMPS_FOLDER"
  schema_v=$(dockerdb psql --no-psqlrc -P pager=off --quiet -tA -U postgres -d "postgres_$env" \
    -c "SELECT version FROM schema_migrations;")
  dump_file="${DUMP_PREFIX}$(date +%Y-%m-%dT%H-%M-%S)_version${schema_v}.gz"

  echo "Dumping database to $dump_file"
  docker exec -i postgres_db_"$PROJECT_PREFIX" pg_dump -U postgres -d "postgres_$env" |
    gzip >"$DUMPS_FOLDER/$dump_file"
}

# Restore the database with the latest dump or `file` for the current environment.
# Args: [file]
x.db.restore() {
  dump_file="$1"
  if [[ -n $dump_file ]]; then
    [[ ! -f $dump_file ]] && err "$dump_file does not exist"
    [[ "$dump_file" != *"$DUMP_PREFIX"* ]] && confirm "${RED}Dump doesn't match prefix '$DUMP_PREFIX'. Continue?${OFF}"
  else
    mkdir -p "$DUMPS_FOLDER"
    latest_dump_file=$(find "$DUMPS_FOLDER"/ -name "$DUMP_PREFIX*.gz" | sort -r | head -n 1)
    if [[ -z "$latest_dump_file" ]]; then
      err "No $DUMP_PREFIX* file found in $DUMPS_FOLDER"
    fi
    dump_file="$latest_dump_file"
  fi

  confirm "Do you want to restore ${YELLOW}$dump_file${OFF} in the ${RED}$env${OFF} environment?"

  drop_and_recreate_db "postgres_$env"
  gunzip -c "$dump_file" | dockerdb psql --no-psqlrc -U postgres -d "postgres_$env"
  # sanity check, but probably better to do it before restoring...
  dump_schema_v=$(dockerdb psql --no-psqlrc -P pager=off -qtAX -U postgres -d "postgres_$env" -c "SELECT version FROM schema_migrations;")
  file_schema_v=$(echo "$dump_file" | sed -E 's/.*_version([0-9]+)\..*/\1/')
  echo "Migration revision: $dump_schema_v"
  if [[ "$dump_schema_v" != "$file_schema_v" ]]; then
    err "Schema version mismatch: dump $dump_schema_v != file $file_schema_v"
  fi
}

########################## e2e ##########################

# Setup E2E Python environment.
x.e2e.sync-dependencies() {
  cd e2e
  python -m venv .venv
  source .venv/bin/activate
  pip install pip-tools
  pip-compile requirements.in
  pip-compile requirements-dev.in
  pip-sync requirements-dev.txt requirements.txt
  cd - >/dev/null
}

# Run E2E tests. Accepts `pytest` parameters.
# Args: [...]
x.e2e.run() {
  name="$PROJECT_PREFIX-e2e"
  cd e2e
  DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain \
    docker build -t "$name" .
  docker run -it --rm --ipc=host -v "$(pwd):/src" "$name" bash -c "pytest $*"
  cd - >/dev/null
}

########################## openapi ##########################

# Validates the project's OpenAPI specification or `spec`.
# Args: [spec]
x.validate() {
  # quite unreliable. e.g. ignored examples inexistent ref.
  # prefer built in kin-openapi validation
  java -jar openapi-generator-cli.jar validate -i "${1:-$SPEC}"
}

# Wrapper for openapi-generator with sane output modifications.
# Args: spec out tpl
x.openapi-generator() {
  local spec="$1"
  local gen_out_dir="$2"
  local template_dir="$3"

  [[ -z $spec ]] && err "openapi-generator: spec required"
  [[ -z $gen_out_dir ]] && err "openapi-generator: out dir required"
  [[ -z $template_dir ]] && err "openapi-generator: template dir required"
  echo "Generating API from $spec"
  echo "Generation directory: $gen_out_dir"
  echo "Template override directory: $template_dir"

  rm -rf "$gen_out_dir/gen"
  # debug has a very small overhead compared to the >1s required per spec
  java -jar "$BIN_DIR"/../openapi-generator-cli.jar generate \
    -g go-gin-server \
    -i "$spec" \
    -o "$gen_out_dir" \
    -t "$template_dir" \
    --additional-properties=packageName=openapi,apiPath=gen,hideGenerationTimestamp=true \
    --enable-post-process-file \
    --global-property=debugModels,debugOperations >debug-openapi.log #>/dev/null \

  mkdir -p "$gen_out_dir"/gen/models
  mkdir -p "$gen_out_dir"/rest
  mkdir -p "$gen_out_dir"/services

  mv "$gen_out_dir"/gen/routers.go "$gen_out_dir"/rest/routers.gen.go

  {
    mv "$gen_out_dir"/gen/model_*.go "$gen_out_dir"/gen/models 2>/dev/null
    goimports -w "$gen_out_dir"/gen/models
  } || echo "No model files found. Skipping"

  rm -rf "$gen_out_dir/api"
}

# Run a diff against the previous OpenAPI spec in the main branch.
# Can also be used to generate changelogs when upgrading major versions.
x.diff-openapi-spec() {
  base_spec="/tmp/openapi.yaml"
  git show "main:$SPEC" >"$base_spec"

  tmp="$(yq .info.version "$base_spec")"
  base_v="${tmp%%.*}"
  tmp=$(yq .info.version "$SPEC")
  rev_v="${tmp%%.*}"
  ((rev_v != base_v)) &&
    echo "${YELLOW}Revision mismatch $rev_v and $base_v, skipping diff.${OFF}" && return

  args="-format text -breaking-only -fail-on-diff -exclude-description -exclude-examples"
  if oasdiff $args -base "$base_spec" -revision $SPEC; then
    echo "${GREEN}No breaking changes found in $SPEC${OFF}"
  else
    echo "${RED}Breaking changes found in $SPEC${OFF}"
    return 1
  fi
}

########################### helpers ###########################

# IMPORTANT: bug in declare -F returns line number of last nested function, if any.
# extracting function here instead...
run_hot_reload() {
  x.run.backend-hot-reload &
  pids+=("$!")
  x.run.frontend &
  pids+=("$!")
}

run_shared_services() {
  cd docker
  docker-compose \
    -p "$PROJECT_PREFIX" \
    -f docker-compose.shared.yml \
    --env-file ../.env."$env" \
    "$@"
  cd - >/dev/null
}

generate_api() {
  cache="$1"
  prefix="$2"
  spec="$3"
  gen_out_dir="$4"
  template_dir="$5"

  invalid_cache=false

  if [[ $force_regen -eq 1 ]]; then
    rm -rf "$cache"
  fi

  mkdir -p "$cache"

  if ! md5sum -c "$cache/$prefix-go-gin-server-templates.md5" >/dev/null; then
    invalid_cache=true
    md5sum "$BIN_DIR"/../internal/go-gin-server-templates/* >"$cache/$prefix-go-gin-server-templates.md5"
  fi
  if ! md5sum -c "$cache/$prefix-openapi.md5" >/dev/null; then
    invalid_cache=true
    md5sum "$BIN_DIR"/../"$SPEC" >"$cache/$prefix-openapi.md5"
  fi

  if [[ $invalid_cache == true ]]; then
    x.openapi-generator \
      "$spec" \
      "$gen_out_dir" \
      "$template_dir"
  fi
}

usage() {
  command_comments_parser() {
    head -$((${lns[$i]} - 1)) $0 |
      tac |
      sed -n '/#/!q;p' |
      tac |
      awk '{$1=$1;print}'
  }

  command_options_comments_parser() {
    tail -n +$((${lns[$i]} + 1)) $0 |
      sed -n '/^[[:blank:]]*#/!q;p' |
      awk '{$1=$1;print}'
  }

  construct_column() {
    comment_parser="$1"
    for i in ${!lns[@]}; do
      comment_paragraph="$($comment_parser)"
      ROWS["${rows[$i]}"]="$comment_paragraph"
      mapfile -t comments <<<"${ROWS[${rows[$i]}]}"
      for comment in "${comments[@]}"; do
        comment="$(clean_comment "$comment")"
        args="-"
        if [[ ${comment,,} == args:* ]]; then
          args=$(clean_args "$comment")
        fi
        ROW_ARGS[${rows[$i]}]="$args"
      done
    done

    for i in "${!rows[@]}"; do
      mapfile -t comments <<<"${ROWS[${rows[$i]}]}"
      for j in "${!comments[@]}"; do
        comment="$(clean_comment "${comments[$j]}")"
        if [[ ${comment,,} == args:* ]]; then
          continue
        fi

        if [[ $j = 0 ]]; then
          docs+=("$(
            printf -- "%s\t%s\t%s" \
              "${rows[$i]}" \
              "${ROW_ARGS[${rows[$i]}]}" \
              "$comment"
          )")
          continue
        fi

        docs+=("$(
          printf -- "%s\t%s\t%s" \
            "" \
            "" \
            "$comment"
        )")
      done
    done

    column -t \
      --separator $'\t' \
      --output-width 150 \
      --table-noextreme C2 \
      --table-noheadings \
      --table-wrap C3 \
      --table-columns C1,C2,C3 < <(printf "    %s\n" "${docs[@]}")
  }

  declare -A ROWS ROW_ARGS
  declare docs rows X_OPTIONS

  for c in "${COMMANDS[@]}"; do
    shopt -s extdebug
    lns+=("$(declare -F x.$c | awk '{print $2}')")
    rows+=("${c}")
    shopt -u extdebug
  done

  x_functions="$(construct_column command_comments_parser)"

  lns=()
  rows=()
  docs=()

  parse_x_options X_OPTIONS

  for c in "${X_OPTIONS[@]}"; do
    lns+=("${c##*)}")
    rows+=("${c%%)*}")
  done

  x_options="$(construct_column command_options_comments_parser)"

  cat <<EOF

$BOLD$UNDERSCORE$(basename $0)$OFF centralizes all relevant project commands.

${BOLD}USAGE:
    $RED$(basename $0) x.function [--x-option ...] args [optional args]$OFF

${BOLD}x.functions:$OFF
$(echo "${x_functions}" |
    sed -E 's/    ([[:alnum:][:punct:]]*)(.*)/    '"$BLUE$BOLD"'\1'"$OFF"'\2''/')

${BOLD}--x-options:$OFF
$(echo "${x_options}" |
      sed -E 's/    ([[:alnum:][:punct:]]*)(.*)/    '"$GREEN$BOLD"'\1'"$OFF"'\2''/')
EOF

}

# gets all --x-options values
parse_x_options() {
  declare -n list="$1" # pass ref by name
  while IFS= read -r line; do
    list+=("$(awk '{$1=$1;print $1 $NF}' <<<"$line")")
  done < <(sed -nr '/.*(--x-[=*[:alnum:]_-]+[)]+).*/{p;=}' $0 | sed '{N;s/\n/ /}')
  mapfile -t list < \
    <(LC_COLLATE=C sort < <(printf "%s\n" "${list[@]}"))
}

clean_comment() {
  tmp="$1"
  tmp="${tmp//\#/}"
  comment="${tmp#* }"
  [[ -z $comment ]] && comment="·"
  # TODO split in % MAX_COMMENT_LEN lines instead, on spaces only.
  ((${#comment} > MAX_COMMENT_LEN)) && comment="${comment:0:MAX_COMMENT_LEN}..."
  echo "$comment"
}

clean_args() {
  tmp="$1"
  tmp="${tmp,,##*args\:}"
  args="${tmp#* }"
  echo "$args"
}

# --------------------- completion and delegation --------------------
#      `complete -C foo foo` > `source <(foo bloated_completion)`

while IFS= read -r line; do
  [[ $line =~ ^declare\ -f\ x\. ]] || continue
  COMMANDS+=("${line##declare -f x.}")
done < <(declare -F)
# sort the array. Mimic file input to sort
mapfile -t COMMANDS < \
  <(LC_COLLATE=C sort < <(printf "%s\n" "${COMMANDS[@]}"))

if [[ -n $COMP_LINE ]]; then
  pre="${COMP_LINE##* }" # the part after the last space in the current command
  cur_commands=(${COMP_LINE%"$pre"})

  for c in "${COMMANDS[@]}"; do
    if [[ " ${cur_commands[*]} " =~ " ${c} " ]]; then
      xfn_specified=true
      break
    fi
  done

  for c in "${COMMANDS[@]}"; do
    test -z "${xfn_specified}" || break
    test -z "${pre}" -o "${c}" != "${c#"${pre}"}" -a "${pre}" != "${c}" && echo "${c}"
  done

  test -z "${xfn_specified}" && exit

  declare __x_options x_options_lines

  parse_x_options x_options_lines

  for c in "${x_options_lines[@]}"; do
    tmp="${c%%)*}"
    xopt="${tmp//\*/}"
    __x_options+=("$xopt")
  done

  declare -A __x_opts_seen
  for cmd in "${cur_commands[@]}"; do
    for opt in ${__x_options[@]}; do
      if [[ "$cmd" == *"$opt"* ]]; then
        __x_opts_seen[$opt]=true
        break
      fi
    done
  done

  for opt in ${__x_options[@]}; do
    [[ -n "${__x_opts_seen[$opt]}" ]] && continue
    # TODO prevent opts that accept values having whitespace added
    [[ ${opt:0:${#pre}} == "${pre,,}" ]] && echo "${opt}"
  done

  exit
fi

# First comment lines automatically added to usage docs.
set +e
while [[ "$#" -gt 0 ]]; do
  case $1 in
  --x-force-regen) # this comment should be ignored
    # Removes generation cache, forcing a new run.
    force_regen=1
    ;;
  --x-no-confirmation)
    # Bypasses confirmation messages.
    export NO_CONFIRMATION=1
    ;;
  --x-env=*)
    # Environment to run commands in. Defaults to "dev".
    # Args: env
    env="${1#--x-env=}"
    valid_envs="dev staging prod ci"
    if [[ ! " ${valid_envs[*]} " =~ " $env " ]]; then
      err "Valid environments: $valid_envs"
    fi
    ;;
  *)
    # will set everything else back
    args+=("$1")
    ;;
  esac
  shift
done
set -e
for arg in ${args[@]}; do
  set -- "$@" "$arg"
done
# applicable to any command
ensure_envvars_set ".env.template" ".env.${env}"
source ".env.$env"

# handle executing x functions
if [[ -n "$1" ]]; then
  declare CMD="$1"
  shift
  for c in "${COMMANDS[@]}"; do
    declare cmd=$(command -v "x.$c")
    if [[ $c == "$CMD" && -n "$cmd" ]]; then
      "x.$CMD" "$@"
      exit $?
    fi
  done
fi

# default to show usage if its a noop
usage
