#!/bin/bash
# shellcheck disable=1091,2155,2068,2086

source "${BASH_SOURCE%/*}/.helpers.sh"
source "${BASH_SOURCE%/*}/scripts/deps-check.sh"

set -Eeo pipefail

trap killgroup SIGINT

pids=()
killgroup() {
  printf "\nkilling spawned processes...\n"
  kill 0
}

ensure_pwd_is_top_level
source ".envrc"

export GIT_USER_ID=danicc097
export GIT_REPO_ID=openapi-go-gin-postgres-sqlc
export GO_POST_PROCESS_FILE="/usr/bin/env gofmt -w -s"
export GENVERS=6.0.1

SPEC="openapi.yaml"
GEN_OUT_DIR="internal"
TEMPLATE_DIR="internal/go-gin-server-templates"
PWD="$(pwd)"
env="dev"
BIN_DIR=$(dirname "${BASH_SOURCE[0]}")
PG_REPO="internal/repos/postgresql"

DUMPS_FOLDER="$HOME/openapi_go_gin_postgres_dumps"
DUMP_PREFIX="dump_${env}_"

MAX_COMMENT_LEN=88

# Check build dependencies are met.
x.check-build-deps() {
  local -i fails
  check.column || { ((fails++)) && true; }
  check.protoc || { ((fails++)) && true; }
  check.bash || { ((fails++)) && true; }
  check.go || { ((fails++)) && true; }
  check.java || { ((fails++)) && true; }
  check.curl || { ((fails++)) && true; }
  check.docker || { ((fails++)) && true; }
  check.docker-compose || { ((fails++)) && true; }
  check.direnv || { ((fails++)) && true; }
  check.yq || { ((fails++)) && true; }
  check.pg_format || { ((fails++)) && true; }
  ((fails == 0)) && echo "${GREEN}ðŸŽ‰ All build dependencies met.${OFF}"
  { ((fails != 0)) && err "${RED}âŒ Missing dependencies.${OFF}"; } || true
}

# Check dependencies and fetch required tools.
x.bootstrap() {
  x.check-build-deps
  x.install-tools
  x.fetch.openapi-generator
  x.fetch.swagger-ui
}

# Install go libraries as runnable programs.
x.install-tools() {
  set -o errexit -eo pipefail

  go install -tags 'postgres' github.com/golang-migrate/migrate/v4/cmd/migrate@v4.15.2
  go install github.com/kyleconroy/sqlc/cmd/sqlc@v1.15.0
  go install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.47.2
  go install github.com/joho/godotenv/cmd/godotenv@latest
  go install github.com/danicc097/air@latest
  go install github.com/xo/xo@latest
  go install github.com/tufin/oasdiff@latest
  go install golang.org/x/tools/cmd/goimports@latest

  go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.27.1
  go install github.com/planetscale/vtprotobuf/cmd/protoc-gen-go-vtproto@v0.2.0
  go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2

  GO111MODULE=off go get -u github.com/maxbrunsfeld/counterfeiter
}

# Fetch openapi-generator jar file.
x.fetch.openapi-generator() {
  local url="https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/$GENVERS/openapi-generator-cli-$GENVERS.jar"
  echo "$url > openapi-generator-cli.jar"
  curl -L "$url" -o openapi-generator-cli.jar
}

# Fetch latest swagger ui bundle.
x.fetch.swagger-ui() {
  name="$(curl --silent "https://api.github.com/repos/swagger-api/swagger-ui/releases/latest" | jq -r ".. .tag_name? // empty")"
  curl -fsSL "github.com/swagger-api/swagger-ui/archive/refs/tags/$name.tar.gz" -o swagger-ui.tar.gz
  tar xf swagger-ui.tar.gz swagger-ui-"${name#*v}"/dist --one-top-level=swagger-ui --strip-components=2
  rm swagger-ui.tar.gz
  mkdir -p internal/static/swagger-ui
  mv swagger-ui/* internal/static/swagger-ui/
  rm -r swagger-ui
}

# Run openapi generator for testdata.
# jar won't output properly if absolute paths are passed from subdir.
x.generate.tests-api() {
  local testdata="$BIN_DIR/../internal/postgen/testdata/openapi_generator"
  local test_dirs=$(find "$testdata" -maxdepth 1 -mindepth 1 -type d -exec basename {} \;)

  cache=".generate-tests-api.cache"
  for test_dir in $test_dirs; do
    generate_api \
      "$cache" \
      "$test_dir" \
      "$testdata/$test_dir/openapi.yaml" \
      "$testdata/$test_dir/internal" \
      "$BIN_DIR/../internal/go-gin-server-templates"
  done
}

# Run post-generation scripts on the internal package.
x.postgen() {
  cache="$1"
  mkdir -p "$cache"
  go build -o postgen "$PWD"/cmd/postgen/main.go
  ./postgen -cachedir="$cache" -env=".env.$env"
  mv "$GEN_OUT_DIR"/gen/api_*.go "$cache/" 2>/dev/null || true
}

# Generate type-safe Go code from SQL.
x.generate.sqlc() {
  { cd $PG_REPO && sqlc generate && cd - >/dev/null; } || err "Failed sqlc generation"
}

# Automatically generate CRUD and By queries based on existing indexes from
# a Postgres schema.
# Does not work with a schema file, database must be up to date.
x.generate.xo() {
  mkdir -p $PG_REPO/gen/crud
  xo schema "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable" \
    -o $PG_REPO/gen/crud
}

# Generate mocks for specified interfaces. Runs are cached to `cachedir`.
# Args: cachedir
x.generate.counterfeiter() {
  # This shouldn't pose any problems, the interface is the only input to counterfeiter.
  cache="$1"

  envvar="internal/envvar/envvar.go"
  services="internal/rest/services.go"
  repos="internal/services/repos.go"

  if ! md5sum -c "$cache/counterfeiter.md5" >/dev/null || [[ $force_regen -eq 1 ]]; then
    counterfeiter -o internal/envvar/envvartesting/provider.gen.go $envvar Provider &
    counterfeiter -o internal/rest/resttesting/authorization.gen.go $services AuthorizationService &
    counterfeiter -o internal/rest/resttesting/authentication.gen.go $services AuthenticationService &
    counterfeiter -o internal/services/servicestesting/user.gen.go $repos UserRepo &
    md5sum $envvar $services $repos >"$cache/counterfeiter.md5" &
    wait
  fi
}

# Generate the required servers/clients for relevant services.
x.generate.proto() {
  local import_path="./python-ml-app-protos/tfidf/v1"
  local filename="python-ml-app-protos/tfidf/v1/service.proto"

  cd internal
  rm -rf ./pb
  mkdir -p ./pb
  # Plugins are no longer supported by protoc-gen-go.
  # Instead protoc-gen-go-grpc and the go package (in proto or via M flag) are required
  protoc \
    --go-grpc_out=./pb/. \
    --go_out=./pb/. \
    --go-grpc_opt=M$filename=$import_path,paths=import \
    --go_opt=M$filename=$import_path,paths=import \
    python-ml-app-protos/tfidf/v1/service.proto
  cd - >/dev/null
}

# Run all codegen and postgen commands for the project.
x.generate() {
  local pids

  x.db.recreate-database

  echo "${MAGENTA}${BOLD}Running codegen and postgen...${OFF}"
  cache=".generate.cache"

  generate_api "$cache" "internal" "$SPEC" "$GEN_OUT_DIR" "$TEMPLATE_DIR"

  go generate ./... &
  pids+=($!)
  x.generate.counterfeiter "$cache" &
  pids+=($!)
  x.generate.sqlc &
  pids+=($!)
  x.generate.xo &
  pids+=($!)
  x.generate.proto &
  pids+=($!)
  x.postgen "$cache" &
  pids+=($!)

  for pid in "${pids[@]}"; do
    wait "$pid"
  done

}

# Lint the entire project.
x.lint() {
  x.lint.sql
}

# Format SQL files.
x.lint.sql() {
  SQL_DIRS=(
    "$PG_REPO/queries"
    "db/migrations"
  )
  for slq_dir in ${SQL_DIRS[@]}; do
    pg_format \
      --spaces 2 \
      --wrap-limit 88 \
      --function-case 2 \
      --keyword-case 1 \
      --placeholder "sqlc\\.(arg|narg)\\(:?[^)]*\\)" \
      --inplace \
      $(find "$slq_dir" -maxdepth 1 -name '*.sql')
  done
}

# Run required backend pre-test setup: services, database cleanup, codegen...
# Can be called independently, e.g. before running tests through an IDE.
x.test.backend-setup() {
  # NOTE: tests run independently in Go so we can't have a function be called and run
  # only once before any test starts
  run_shared_services up -d --remove-orphans
  x.generate
  drop_and_recreate_db "postgres_test"
  x.generate.tests-api
}

# Test the entire project. Accepts `go test` parameters.
# Args: [...]
x.test() {
  x.test.backend-setup
  APP_ENV="$env" go test "$@" ./...
}

# Test and build the entire project.
x.build() {
  x.lint
  x.test ""
  go build -o rest-server "$PWD"/cmd/rest-server
}

# Run backend with hot-reloading.
x.run.backend-hot-reload() {
  run_shared_services up -d --remove-orphans
  # TODO new include_files flag in fork, e.g. for openapi.yaml.
  # else generated .yaml files trigger rebuild.
  # --build.include_files "openapi.yaml" \
  # NOTE: building binary very unreliable, leads to bin not found.
  air \
    --build.pre_build_cmd "bin/project generate" \
    --build.cmd "" \
    --build.bin "go run ./cmd/rest-server/ -env=.env.$env" \
    --build.include_ext "go" \
    --build.exclude_regex ".gen.go,_test.go" \
    --build.exclude_dir ".git,tmp,internal/gen,internal/pb,$PG_REPO/gen,tests/testdata,frontend,*.cache" \
    --build.stop_watch "internal/rest/,internal/services/" \
    --build.delay 1000 \
    --build.exclude_unchanged "true" |
    sed -e "s/^/${BLUE}[Air]${OFF} /"
}

# Run frontend with hot-reloading.
x.run.frontend() {
  set -a
  # export to replace config with envvars
  source ".env.$env"
  set +a

  cd frontend
  pnpm run generate

  pnpm run dev |
    sed -e "s/^/${GREEN}[Vite]${OFF} /"
}

# Run all project services with hot reload enabled in dev mode.
x.run-dev() {
  env="dev"

  run_hot_reload

  next_allowed_run=$(date +%s)
  latency=3
  # close_write event, else duplicated, tripl. events -> race condition
  while true; do
    inotifywait \
      --monitor "$SPEC" \
      --event=close_write \
      --format='%T %f' \
      --timefmt='%s' |
      while read -r event_time event_file 2>/dev/null || sleep $latency; do
        if [[ $event_time -ge $next_allowed_run ]]; then
          next_allowed_run=$(date --date="${latency}sec" +%s)

          for pid in "${pids[@]}"; do
            # air and vite spawn processes as well, need to kill those (whose parent is pid), kill $pid will not kill children. pkill -P would also work
            kill $(list_descendants $pid)
          done
          pids=()

          run_hot_reload
        fi
      done
  done
}

# Run project in production mode.
x.run-prod() {
  env="prod"

  docker network create traefik-net 2>/dev/null || true
  run_shared_services up -d --remove-orphans
  x.db.recreate-database

  cd frontend && pnpm run generate && cd - >/dev/null
  x.generate

  DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain docker-compose \
    --project-name "$PROJECT_PREFIX"_"$env" \
    -f docker-compose."$env".yml \
    --env-file ".env.$env" \
    up -d --build

  echo "Migrations: $(x.migrate up)"
}

# Remove running project containers, including shared ones between environments.
x.stop-project() {
  run_shared_services down --remove-orphans
}

# Checks before release:
# - Magic keyword "STOPSHIP" not found in tracked files.
x.release() {
  x.search-stopship "STOPSHIP" &
  pids+=($!)
  go mod verify &
  pids+=($!)

  for pid in "${pids[@]}"; do
    wait "$pid"
  done
}

# Block build if magic keyword is found in any file
# Args: keyword
x.search-stopship() {
  stopship_keyword="$1"
  local matches
  matches=$(find "$(git rev-parse --show-toplevel)" \
    -type f \
    -not -path '**/.git/*' \
    -not -path '**/.venv/*' \
    -not -path '**/node_modules/*' \
    -not -path '**/build/*' \
    -not -path '**/*.pyc' \
    -not -path "$0" \
    -not -exec git check-ignore -q --no-index {} \; \
    -exec grep -i --files-with-matches --regexp="$stopship_keyword" {} \;)
  if [[ -n $matches ]]; then
    echo "${RED}'$stopship_keyword'${OFF} found in tracked files."
    echo "Please fix all related issues in the following files:"
    printf "\t %s\n" $matches
    exit 1
  fi
}

########################## migrations ##########################

# Wrapper for golang-migrate with predefined configuration.
x.migrate() {
  migrate \
    -path db/migrations/ \
    -database "postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@localhost:$DB_PORT/$POSTGRES_DB?sslmode=disable" \
    "$@"
}

# Create a new migration file with the given `name`.
# Args: name
x.migrate.create-migration() {
  tmp="$*"
  tmp="${tmp// /_}"
  name="${tmp,,}"
  [[ -z $name ]] && err "Please provide a migration name"
  x.migrate create -ext sql -dir db/migrations/ "$name"
}

########################## db ##########################

# Create a new database in the current environment if it doesn't exist
# and stops its running processes if any.
x.db.recreate-database() {
  create_db_if_not_exists "postgres_$env"
  stop_db_processes "postgres_$env"
}

# Backup the database for the current environment.
x.db.dump() {
  running_dumps=$(dockerdb psql --no-psqlrc -P pager=off --quiet -tA -U postgres -d "postgres_$env" \
    -c "SELECT pid FROM pg_stat_activity WHERE application_name = 'pg_dump';")
  if [[ "$running_dumps" != "" ]]; then
    echo "pg_dump is already running, aborting new dump"
    exit 1
  fi

  mkdir -p "$DUMPS_FOLDER"
  schema_v=$(dockerdb psql --no-psqlrc -P pager=off --quiet -tA -U postgres -d "postgres_$env" \
    -c "SELECT version FROM schema_migrations;")
  dump_file="${DUMP_PREFIX}$(date +%Y-%m-%dT%H-%M-%S)_version${schema_v}.gz"

  echo "Dumping database to $dump_file"
  docker exec -i postgres_db_"$PROJECT_PREFIX" pg_dump -U postgres -d "postgres_$env" |
    gzip >"$DUMPS_FOLDER/$dump_file"
}

# Restore the database with the latest dump or `file` for the current environment.
# Args: [file]
x.db.restore() {
  dump_file="$1"
  if [[ -n $dump_file ]]; then
    [[ ! -f $dump_file ]] && err "$dump_file does not exist"
    [[ "$dump_file" != *"$DUMP_PREFIX"* ]] && confirm "${RED}Dump doesn't match prefix '$DUMP_PREFIX'. Continue?${OFF}"
  else
    mkdir -p "$DUMPS_FOLDER"
    latest_dump_file=$(find "$DUMPS_FOLDER"/ -name "$DUMP_PREFIX*.gz" | sort -r | head -n 1)
    if [[ -z "$latest_dump_file" ]]; then
      err "No $DUMP_PREFIX* file found in $DUMPS_FOLDER"
    fi
    dump_file="$latest_dump_file"
  fi

  confirm "Do you want to restore ${YELLOW}$dump_file${OFF} in the ${RED}$env${OFF} environment?"

  drop_and_recreate_db "postgres_$env"
  gunzip -c "$dump_file" | dockerdb psql --no-psqlrc -U postgres -d "postgres_$env"
  # sanity check, but probably better to do it before restoring...
  dump_schema_v=$(dockerdb psql --no-psqlrc -P pager=off -qtAX -U postgres -d "postgres_$env" -c "SELECT version FROM schema_migrations;")
  file_schema_v=$(echo "$dump_file" | sed -E 's/.*_version([0-9]+)\..*/\1/')
  echo "Migration revision: $dump_schema_v"
  if [[ "$dump_schema_v" != "$file_schema_v" ]]; then
    err "Schema version mismatch: dump $dump_schema_v != file $file_schema_v"
  fi
}

########################## e2e ##########################

# Setup E2E Python environment.
x.e2e.sync-dependencies() {
  cd e2e
  python -m venv .venv
  source .venv/bin/activate
  pip install pip-tools
  pip-compile requirements.in
  pip-compile requirements-dev.in
  pip-sync requirements-dev.txt requirements.txt
  cd - >/dev/null
}

# Run E2E tests. Accepts `pytest` parameters.
# Args: [...]
x.e2e.run() {
  name="$PROJECT_PREFIX-e2e"
  cd e2e
  DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain \
    docker build -t "$name" .
  docker run -it --rm --ipc=host -v "$(pwd):/src" "$name" bash -c "pytest $*"
  cd - >/dev/null
}

########################## openapi ##########################

# Validates the project's OpenAPI specification or `spec`.
# Args: [spec]
x.validate() {
  # quite unreliable. e.g. ignored examples inexistent ref.
  # prefer built in kin-openapi validation
  java -jar openapi-generator-cli.jar validate -i "${1:-$SPEC}"
}

# Wrapper for openapi-generator with sane output modifications.
# Args: spec out tpl
x.openapi-generator() {
  local spec="$1"
  local gen_out_dir="$2"
  local template_dir="$3"

  [[ -z $spec ]] && err "openapi-generator: spec required"
  [[ -z $gen_out_dir ]] && err "openapi-generator: out dir required"
  [[ -z $template_dir ]] && err "openapi-generator: template dir required"
  echo "Generating API from $spec"
  echo "Generation directory: $gen_out_dir"
  echo "Template override directory: $template_dir"

  rm -rf "$gen_out_dir/gen"
  # debug has a very small overhead compared to the >1s required per spec
  java -jar "$BIN_DIR"/../openapi-generator-cli.jar generate \
    -g go-gin-server \
    -i "$spec" \
    -o "$gen_out_dir" \
    -t "$template_dir" \
    --additional-properties=packageName=openapi,apiPath=gen,hideGenerationTimestamp=true \
    --enable-post-process-file \
    --global-property=debugModels,debugOperations >debug-openapi.log #>/dev/null \

  mkdir -p "$gen_out_dir"/gen/models
  mkdir -p "$gen_out_dir"/rest
  mkdir -p "$gen_out_dir"/services

  mv "$gen_out_dir"/gen/routers.go "$gen_out_dir"/rest/routers.gen.go

  {
    mv "$gen_out_dir"/gen/model_*.go "$gen_out_dir"/gen/models 2>/dev/null
    goimports -w "$gen_out_dir"/gen/models
  } || echo "No model files found. Skipping"

  rm -rf "$gen_out_dir/api"
}

# Run a diff against the previous OpenAPI spec in the main branch.
# Can also be used to generate changelogs when upgrading major versions.
x.diff-openapi-spec() {
  base_spec="/tmp/openapi.yaml"
  git show "main:$SPEC" >"$base_spec"

  tmp="$(yq .info.version "$base_spec")"
  base_v="${tmp%%.*}"
  tmp=$(yq .info.version "$SPEC")
  rev_v="${tmp%%.*}"
  ((rev_v != base_v)) &&
    echo "${YELLOW}Revision mismatch $rev_v and $base_v, skipping diff.${OFF}" && return

  args="-format text -breaking-only -fail-on-diff -exclude-description -exclude-examples"
  if oasdiff $args -base "$base_spec" -revision $SPEC; then
    echo "${GREEN}No breaking changes found in $SPEC${OFF}"
  else
    echo "${RED}Breaking changes found in $SPEC${OFF}"
    return 1
  fi
}

########################### helpers ###########################

# IMPORTANT: bug in declare -F returns line number of last nested function, if any.
# extracting function here instead...
run_hot_reload() {
  x.run.backend-hot-reload &
  pids+=("$!")
  x.run.frontend &
  pids+=("$!")
}

run_shared_services() {
  cd docker
  docker-compose \
    -p "$PROJECT_PREFIX" \
    -f docker-compose.shared.yml \
    --env-file ../.env."$env" \
    "$@"
  cd - >/dev/null
}

generate_api() {
  cache="$1"
  prefix="$2"
  spec="$3"
  gen_out_dir="$4"
  template_dir="$5"

  invalid_cache=false
  mkdir -p "$cache"

  if ! md5sum -c "$cache/$prefix-go-gin-server-templates.md5" >/dev/null || [[ $force_regen -eq 1 ]]; then
    invalid_cache=true
    md5sum "$BIN_DIR"/../internal/go-gin-server-templates/* >"$cache/$prefix-go-gin-server-templates.md5"
  fi
  if ! md5sum -c "$cache/$prefix-openapi.md5" >/dev/null || [[ $force_regen -eq 1 ]]; then
    invalid_cache=true
    md5sum "$BIN_DIR"/../"$SPEC" >"$cache/$prefix-openapi.md5"
  fi

  if [[ $invalid_cache == true ]]; then
    x.openapi-generator \
      "$spec" \
      "$gen_out_dir" \
      "$template_dir"
  fi
}

usage() {
  command_comments_parser() {
    head -$((${lns[$i]} - 1)) $0 |
      tac |
      sed -n '/#/!q;p' |
      tac |
      awk '{$1=$1;print}'
  }

  command_options_comments_parser() {
    tail -n +$((${lns[$i]} + 1)) $0 |
      sed -n '/^[[:blank:]]*#/!q;p' |
      awk '{$1=$1;print}'
  }

  construct_column() {
    comment_parser="$1"
    for i in ${!lns[@]}; do
      comment_paragraph="$($comment_parser)"
      ROWS["${rows[$i]}"]="$comment_paragraph"
      mapfile -t comments <<<"${ROWS[${rows[$i]}]}"
      for comment in "${comments[@]}"; do
        comment="$(clean_comment "$comment")"
        args="-"
        if [[ ${comment,,} == args:* ]]; then
          args=$(clean_args "$comment")
        fi
        ROW_ARGS[${rows[$i]}]="$args"
      done
    done

    for i in "${!rows[@]}"; do
      mapfile -t comments <<<"${ROWS[${rows[$i]}]}"
      for j in "${!comments[@]}"; do
        comment="$(clean_comment "${comments[$j]}")"
        if [[ ${comment,,} == args:* ]]; then
          continue
        fi

        if [[ $j = 0 ]]; then
          docs+=("$(
            printf -- "%s\t%s\t%s" \
              "${rows[$i]}" \
              "${ROW_ARGS[${rows[$i]}]}" \
              "$comment"
          )")
          continue
        fi

        docs+=("$(
          printf -- "%s\t%s\t%s" \
            "" \
            "" \
            "$comment"
        )")
      done
    done

    column -t \
      --separator $'\t' \
      --output-width 150 \
      --table-noextreme C2 \
      --table-noheadings \
      --table-wrap C3 \
      --table-columns C1,C2,C3 < <(printf "    %s\n" "${docs[@]}")
  }

  declare -A ROWS ROW_ARGS
  declare docs rows X_OPTIONS

  for c in "${COMMANDS[@]}"; do
    shopt -s extdebug
    lns+=("$(declare -F x.$c | awk '{print $2}')")
    rows+=("${c}")
    shopt -u extdebug
  done

  x_functions="$(construct_column command_comments_parser)"

  lns=()
  rows=()
  docs=()

  parse_x_options X_OPTIONS

  for c in "${X_OPTIONS[@]}"; do
    lns+=("${c##*)}")
    rows+=("${c%%)*}")
  done

  x_options="$(construct_column command_options_comments_parser)"

  cat <<EOF

$BOLD$UNDERSCORE$(basename $0)$OFF centralizes all relevant project commands.

${BOLD}USAGE:
    $RED$(basename $0) x.function [--x-option ...] args [optional args]$OFF

${BOLD}x.functions:$OFF
$(echo "${x_functions}" |
    sed -E 's/    ([[:alnum:][:punct:]]*)(.*)/    '"$BLUE$BOLD"'\1'"$OFF"'\2''/')

${BOLD}--x-options:$OFF
$(echo "${x_options}" |
      sed -E 's/    ([[:alnum:][:punct:]]*)(.*)/    '"$GREEN$BOLD"'\1'"$OFF"'\2''/')
EOF

}

# gets all --x-options values
parse_x_options() {
  declare -n list="$1" # pass ref by name
  while IFS= read -r line; do
    list+=("$(awk '{$1=$1;print $1 $NF}' <<<"$line")")
  done < <(sed -nr '/.*(--x-[=*[:alnum:]_-]+[)]+).*/{p;=}' $0 | sed '{N;s/\n/ /}')
  mapfile -t list < \
    <(LC_COLLATE=C sort < <(printf "%s\n" "${list[@]}"))
}

clean_comment() {
  tmp="$1"
  tmp="${tmp//\#/}"
  comment="${tmp#* }"
  [[ -z $comment ]] && comment="Â·"
  # TODO split in % MAX_COMMENT_LEN lines instead, on spaces only.
  ((${#comment} > MAX_COMMENT_LEN)) && comment="${comment:0:MAX_COMMENT_LEN}..."
  echo "$comment"
}

clean_args() {
  tmp="$1"
  tmp="${tmp,,##*args\:}"
  args="${tmp#* }"
  echo "$args"
}

# --------------------- completion and delegation --------------------
#      `complete -C foo foo` > `source <(foo bloated_completion)`

while IFS= read -r line; do
  [[ $line =~ ^declare\ -f\ x\. ]] || continue
  COMMANDS+=("${line##declare -f x.}")
done < <(declare -F)
# sort the array. Mimic file input to sort
mapfile -t COMMANDS < \
  <(LC_COLLATE=C sort < <(printf "%s\n" "${COMMANDS[@]}"))

if [[ -n $COMP_LINE ]]; then
  pre="${COMP_LINE##* }" # the part after the last space in the current command
  cur_commands=(${COMP_LINE%"$pre"})

  for c in "${COMMANDS[@]}"; do
    if [[ " ${cur_commands[*]} " =~ " ${c} " ]]; then
      xfn_specified=true
      break
    fi
  done

  for c in "${COMMANDS[@]}"; do
    test -z "${xfn_specified}" || break
    test -z "${pre}" -o "${c}" != "${c#"${pre}"}" -a "${pre}" != "${c}" && echo "${c}"
  done

  test -z "${xfn_specified}" && exit

  declare __x_options x_options_lines

  parse_x_options x_options_lines

  for c in "${x_options_lines[@]}"; do
    tmp="${c%%)*}"
    xopt="${tmp//\*/}"
    __x_options+=("$xopt")
  done

  declare -A __x_opts_seen
  for cmd in "${cur_commands[@]}"; do
    for opt in ${__x_options[@]}; do
      if [[ "$cmd" == *"$opt"* ]]; then
        __x_opts_seen[$opt]=true
        break
      fi
    done
  done

  for opt in ${__x_options[@]}; do
    [[ -n "${__x_opts_seen[$opt]}" ]] && continue
    # TODO prevent opts that accept values having whitespace added
    [[ ${opt:0:${#pre}} == "${pre,,}" ]] && echo "${opt}"
  done

  exit
fi

# First comment lines automatically added to usage docs.
set +e
while [[ "$#" -gt 0 ]]; do
  case $1 in
  --x-force-regen) # this comment should be ignored
    # Removes generation cache, forcing a new run.
    force_regen=1
    ;;
  --x-no-confirmation)
    # Bypasses confirmation messages.
    export NO_CONFIRMATION=1
    ;;
  --x-env=*)
    # Environment to run commands in. Defaults to "dev".
    # Args: env
    env="${1#--x-env=}"
    valid_envs="dev staging prod ci"
    if [[ ! " ${valid_envs[*]} " =~ " $env " ]]; then
      err "Valid environments: $valid_envs"
    fi
    ;;
  *)
    # will set everything else back
    args+=("$1")
    ;;
  esac
  shift
done
set -e
for arg in ${args[@]}; do
  set -- "$@" "$arg"
done
# applicable to any command
ensure_envvars_set ".env.template" ".env.${env}"
source ".env.$env"

# handle executing x functions
if [[ -n "$1" ]]; then
  declare CMD="$1"
  shift
  for c in "${COMMANDS[@]}"; do
    declare cmd=$(command -v "x.$c")
    if [[ $c == "$CMD" && -n "$cmd" ]]; then
      "x.$CMD" "$@"
      exit $?
    fi
  done
fi

# default to show usage if its a noop
usage
